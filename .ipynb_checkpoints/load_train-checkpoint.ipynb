{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This project takes in the MNIST training dataset and does stuff\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import torch;\n",
    "\n",
    "train_df = pd.read_csv('digit-recognizer/train.csv')\n",
    "\n",
    "train_labels = train_df['label']\n",
    "train_df.drop(['label'],inplace=True, axis=1)\n",
    "\n",
    "np_train = train_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(np_train[0])) # this is the shape for each entry in the training dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'training_data.p'\n",
    "\n",
    "### loading the data if it's been previously generated ###\n",
    "try:\n",
    "    infile = open(filename,'rb')\n",
    "    train_input = pickle.load(infile)\n",
    "    infile.close()\n",
    "\n",
    "### Generating and saving the data ###\n",
    "except:\n",
    "    two_d = np.reshape(np_train[0],[1,28,28])\n",
    "    train_input = two_d\n",
    "\n",
    "    for ind in tqdm(range(1,np.shape(np_train)[0])):\n",
    "    #     if ind == 10:\n",
    "    #         break\n",
    "        two_d = np.reshape(np_train[ind],[1,28,28])\n",
    "        train_input = np.concatenate((train_input, two_d), axis = 0)\n",
    "\n",
    "    print(np.shape(train_input))\n",
    "\n",
    "    outfile = open(filename,'wb')\n",
    "    pickle.dump(train_input, outfile)\n",
    "    outfile.close()\n",
    "\n",
    "    print('saved successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb6943e6070>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(train_input[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_input, train_labels, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    from https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) #in channels, out channels (AKA # of kernels), kernel size\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) \n",
    "        # an affine operation: y = Wx + b\n",
    "        #self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120) # 4*4 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "#         x = F.max_pool2d(F.leaky_relu(self.conv1(x), 0.01), (2, 2)) #trying with leaky\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "#         x = F.max_pool2d(F.leaky_relu(self.conv2(x), 0.01), 2) #trying with leaky\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "#         x = F.leaky_relu(self.fc1(x), 0.01)\n",
    "#         x = F.leaky_relu(self.fc2(x), 0.01)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0069,  0.0406, -0.1498, -0.0071,  0.0430, -0.0599,  0.0194,  0.0951,\n",
      "         -0.1409, -0.0665]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 28, 28)\n",
    "#input = torch.randn(28, 28)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8366, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conv1.bias.grad after backward\n",
      "tensor([-0.0084, -0.0294, -0.0020, -0.0164,  0.0121,  0.0048])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600, 28, 28)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 28])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight [6, 1, 5, 5], but got 2-dimensional input of size [28, 28] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-f2c3012d8608>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mx_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Compute and print loss.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-a7b7534db81b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Max pooling over a (2, 2) window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;31m#         x = F.max_pool2d(F.leaky_relu(self.conv1(x), 0.01), (2, 2)) #trying with leaky\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# If the size is a square, you can specify with a single number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    437\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 439\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    440\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [6, 1, 5, 5], but got 2-dimensional input of size [28, 28] instead"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# # in your training loop:\n",
    "# optimizer.zero_grad()   # zero the gradient buffers\n",
    "# output = net(input)\n",
    "# loss = criterion(output, target)\n",
    "# loss.backward()\n",
    "# optimizer.step()  \n",
    "    \n",
    "for idx in range(np.shape(X_train)[0]): # from https://pytorch.org/tutorials/beginner/pytorch_with_examples.html\n",
    "    # Forward pass: compute predicted y by passing x to the model.\n",
    "    x_val = torch.tensor(X_train[idx])\n",
    "    y_pred = net(x_val)\n",
    "\n",
    "    # Compute and print loss.\n",
    "    loss = loss_fn(y_pred, y_train[idx])\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables it will update (which are the learnable\n",
    "    # weights of the model). This is because by default, gradients are\n",
    "    # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
    "    # is called. Checkout docs of torch.autograd.backward for more details.\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to model\n",
    "    # parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "linear_layer = net[0]\n",
    "print(f'Result: y = {linear_layer.bias.item()} + {linear_layer.weight[:, 0].item()} x + {linear_layer.weight[:, 1].item()} x^2 + {linear_layer.weight[:, 2].item()} x^3')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
