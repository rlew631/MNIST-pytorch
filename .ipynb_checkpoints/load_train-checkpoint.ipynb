{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This project takes in the MNIST training dataset and does stuff\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "train_df = pd.read_csv('digit-recognizer/train.csv')\n",
    "\n",
    "train_labels = train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 4, 0, 0, 7, 3, 5, 3, 8, 9, 1, 3, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.values[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'training_data.p'\n",
    "\n",
    "### loading the data if it's been previously generated ###\n",
    "\n",
    "try:\n",
    "    infile = open(filename,'rb')\n",
    "    train_input = pickle.load(infile)\n",
    "    infile.close()\n",
    "\n",
    "### Generating and saving the data ###\n",
    "except:\n",
    "    train_df.drop(['label'],inplace=True, axis=1)\n",
    "    np_train = train_df.to_numpy()\n",
    "    \n",
    "    two_d = np.reshape(np_train[0],[1,28,28])\n",
    "    train_input = two_d\n",
    "\n",
    "    for ind in tqdm(range(1,np.shape(np_train)[0])):\n",
    "    #     if ind == 10:\n",
    "    #         break\n",
    "        two_d = np.reshape(np_train[ind],[1,28,28])\n",
    "        train_input = np.concatenate((train_input, two_d), axis = 0)\n",
    "\n",
    "    print(np.shape(train_input))\n",
    "\n",
    "    outfile = open(filename,'wb')\n",
    "    pickle.dump(train_input, outfile)\n",
    "    outfile.close()\n",
    "\n",
    "    print('saved successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f86549a8fa0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(train_input[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    from https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) #in channels, out channels (AKA # of kernels), kernel size\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) \n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120) # 4*4 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "#         x = x.double()\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2) # max_pool2d(__,2) halves the height and width\n",
    "#         x = F.max_pool2d(F.leaky_relu(self.conv1(x), 0.01), (2, 2)) #trying with leaky\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "#         x = F.max_pool2d(F.leaky_relu(self.conv2(x), 0.01), 2) #trying with leaky\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "#         x = F.leaky_relu(self.fc1(x), 0.01)\n",
    "#         x = F.leaky_relu(self.fc2(x), 0.01)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0798,  0.0272, -0.0219, -0.0451, -0.0631, -0.0714,  0.0434, -0.0780,\n",
      "         -0.0254,  0.0821]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 28, 28)\n",
    "#input = torch.randn(28, 28)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9849, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conv1.bias.grad after backward\n",
      "tensor([ 0.0025,  0.0009, -0.0036,  0.0014,  0.0091, -0.0180])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape: (33600, 28, 28)\n",
      "training labels shape: (33600,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_input, train_labels.values, test_size=0.20, random_state=42)\n",
    "print(f'training data shape: {np.shape(X_train)}')\n",
    "print(f'training labels shape: {np.shape(y_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html for dataset info\n",
    "# looks like pytorch likes to have datasets structured as classes and is mor picky than TF\n",
    "\n",
    "class CustomMNISTDataset():\n",
    "    def __init__(self, labels, imgs):\n",
    "        temp_imgs = ((imgs-128)/128).astype(np.float32)\n",
    "        self.imgs = torch.unsqueeze(torch.from_numpy(temp_imgs), 1)\n",
    "#         self.labels = labels\n",
    "        self.labels = F.one_hot(torch.tensor(labels), num_classes=10) # one hot encodes the labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return ( \n",
    "            self.imgs[idx],\n",
    "            self.labels[idx]\n",
    "        )\n",
    "\n",
    "train_DS = CustomMNISTDataset(labels = y_train, imgs = X_train)\n",
    "test_DS = CustomMNISTDataset(labels = y_test, imgs = X_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_DS, batch_size=50)\n",
    "val_loader = torch.utils.data.DataLoader(test_DS, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_DS.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f86d8409290>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 3\n",
    "batch_size_train = 50\n",
    "batch_size_test = 10\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    net.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = net(data)\n",
    "#         loss = F.nll_loss(output, target)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.item()), end='\\r')\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append(\n",
    "            (batch_idx*50) + ((epoch-1)*len(train_loader.dataset)))\n",
    "#             torch.save(network.state_dict(), '/results/model.pth')\n",
    "#             torch.save(optimizer.state_dict(), '/results/optimizer.pth')\n",
    "            ### Figure out how to save later, fuck dis shit for now ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            output = net(data)\n",
    "#             test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            test_loss = criterion(output, target).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 1]' is invalid for input of size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-26b4aad1314a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-20e439f175db>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtest_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 1]' is invalid for input of size 10"
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
