{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This project takes in the MNIST training dataset and does stuff\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "train_df = pd.read_csv('digit-recognizer/train.csv')\n",
    "\n",
    "train_labels = train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 4, 0, 0, 7, 3, 5, 3, 8, 9, 1, 3, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.values[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'training_data.p'\n",
    "\n",
    "### loading the data if it's been previously generated ###\n",
    "\n",
    "try:\n",
    "    infile = open(filename,'rb')\n",
    "    train_input = pickle.load(infile)\n",
    "    infile.close()\n",
    "\n",
    "### Generating and saving the data ###\n",
    "except:\n",
    "    train_df.drop(['label'],inplace=True, axis=1)\n",
    "    np_train = train_df.to_numpy()\n",
    "    \n",
    "    two_d = np.reshape(np_train[0],[1,28,28])\n",
    "    train_input = two_d\n",
    "\n",
    "    for ind in tqdm(range(1,np.shape(np_train)[0])):\n",
    "    #     if ind == 10:\n",
    "    #         break\n",
    "        two_d = np.reshape(np_train[ind],[1,28,28])\n",
    "        train_input = np.concatenate((train_input, two_d), axis = 0)\n",
    "\n",
    "    print(np.shape(train_input))\n",
    "\n",
    "    outfile = open(filename,'wb')\n",
    "    pickle.dump(train_input, outfile)\n",
    "    outfile.close()\n",
    "\n",
    "    print('saved successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8f78857c70>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(train_input[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    from https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) #in channels, out channels (AKA # of kernels), kernel size\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) \n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120) # 4*4 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "#         x = x.double()\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2) # max_pool2d(__,2) halves the height and width\n",
    "#         x = F.max_pool2d(F.leaky_relu(self.conv1(x), 0.01), (2, 2)) #trying with leaky\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "#         x = F.max_pool2d(F.leaky_relu(self.conv2(x), 0.01), 2) #trying with leaky\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "#         x = F.leaky_relu(self.fc1(x), 0.01)\n",
    "#         x = F.leaky_relu(self.fc2(x), 0.01)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0815, -0.0308, -0.0352,  0.0124,  0.0421, -0.0004, -0.0641,  0.0751,\n",
      "         -0.0014, -0.0056]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rlew/opt/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 28, 28)\n",
    "#input = torch.randn(28, 28)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9323, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conv1.bias.grad after backward\n",
      "tensor([ 0.0175, -0.0139, -0.0014, -0.0038,  0.0009,  0.0011])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape: (33600, 28, 28)\n",
      "training labels shape: (33600,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_input, train_labels.values, test_size=0.20, random_state=42)\n",
    "print(f'training data shape: {np.shape(X_train)}')\n",
    "print(f'training labels shape: {np.shape(y_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html for dataset info\n",
    "# looks like pytorch likes to have datasets structured as classes and is mor picky than TF\n",
    "\n",
    "class CustomMNISTDataset():\n",
    "    def __init__(self, labels, imgs):\n",
    "        temp_imgs = ((imgs-128)/128).astype(np.float32)\n",
    "        self.imgs = torch.unsqueeze(torch.from_numpy(temp_imgs), 1)\n",
    "        self.labels = labels\n",
    "#         self.labels = F.one_hot(torch.tensor(labels), num_classes=10) # one hot encodes the labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return ( \n",
    "            self.imgs[idx],\n",
    "            self.labels[idx]\n",
    "        )\n",
    "\n",
    "# train_DS = CustomMNISTDataset(labels = y_train, imgs = X_train)\n",
    "# test_DS = CustomMNISTDataset(labels = y_test, imgs = X_test)\n",
    "\n",
    "train_DS = CustomMNISTDataset(labels = torch.from_numpy(y_train).long(), imgs = X_train)\n",
    "test_DS = CustomMNISTDataset(labels = torch.from_numpy(y_test).long(), imgs = X_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_DS, batch_size=50)\n",
    "val_loader = torch.utils.data.DataLoader(test_DS, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_acc(y_pred, y_test):\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n",
    "    \n",
    "    correct_pred = (y_pred_tags == y_test).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    \n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 3\n",
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_stats = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}\n",
    "loss_stats = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:13<00:27, 13.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.23116 | Val Loss: 0.19357 | Train Acc: 93.027| Val Acc: 94.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:31<00:15, 15.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002: | Train Loss: 0.12234 | Val Loss: 0.12127 | Train Acc: 96.705| Val Acc: 96.738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:48<00:00, 16.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003: | Train Loss: 0.11105 | Val Loss: 0.10787 | Train Acc: 97.036| Val Acc: 97.238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Begin training.\")\n",
    "for e in tqdm(range(1, n_epochs+1)):\n",
    "    \n",
    "    # TRAINING\n",
    "    train_epoch_loss = 0\n",
    "    train_epoch_acc = 0\n",
    "    net.train()\n",
    "    for X_train_batch, y_train_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_train_pred = net(X_train_batch)\n",
    "        \n",
    "        train_loss = criterion(y_train_pred, y_train_batch)\n",
    "        train_acc = multi_acc(y_train_pred, y_train_batch)\n",
    "        \n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_epoch_loss += train_loss.item()\n",
    "        train_epoch_acc += train_acc.item()\n",
    "        \n",
    "        \n",
    "    # VALIDATION    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        val_epoch_loss = 0\n",
    "        val_epoch_acc = 0\n",
    "        \n",
    "        net.eval()\n",
    "        for X_val_batch, y_val_batch in val_loader:\n",
    "            \n",
    "            y_val_pred = net(X_val_batch)\n",
    "                        \n",
    "            val_loss = criterion(y_val_pred, y_val_batch)\n",
    "            val_acc = multi_acc(y_val_pred, y_val_batch)\n",
    "            \n",
    "            val_epoch_loss += val_loss.item()\n",
    "            val_epoch_acc += val_acc.item()\n",
    "    loss_stats['train'].append(train_epoch_loss/len(train_loader))\n",
    "    loss_stats['val'].append(val_epoch_loss/len(val_loader))\n",
    "    accuracy_stats['train'].append(train_epoch_acc/len(train_loader))\n",
    "    accuracy_stats['val'].append(val_epoch_acc/len(val_loader))\n",
    "                              \n",
    "    \n",
    "    print(f'Epoch {e+0:03}: | Train Loss: {train_epoch_loss/len(train_loader):.5f} | Val Loss: {val_epoch_loss/len(val_loader):.5f} | Train Acc: {train_epoch_acc/len(train_loader):.3f}| Val Acc: {val_epoch_acc/len(val_loader):.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
