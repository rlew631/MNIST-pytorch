{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This project takes in the MNIST training dataset and does stuff\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import torch;\n",
    "\n",
    "train_df = pd.read_csv('digit-recognizer/train.csv')\n",
    "\n",
    "train_labels = train_df['label']\n",
    "train_df.drop(['label'],inplace=True, axis=1)\n",
    "\n",
    "np_train = train_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(np_train[0])) # this is the shape for each entry in the training dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'training_data.p'\n",
    "\n",
    "### loading the data if it's been previously generated ###\n",
    "try:\n",
    "    infile = open(filename,'rb')\n",
    "    train_input = pickle.load(infile)\n",
    "    infile.close()\n",
    "\n",
    "### Generating and saving the data ###\n",
    "except:\n",
    "    two_d = np.reshape(np_train[0],[1,28,28])\n",
    "    train_input = two_d\n",
    "\n",
    "    for ind in tqdm(range(1,np.shape(np_train)[0])):\n",
    "    #     if ind == 10:\n",
    "    #         break\n",
    "        two_d = np.reshape(np_train[ind],[1,28,28])\n",
    "        train_input = np.concatenate((train_input, two_d), axis = 0)\n",
    "\n",
    "    print(np.shape(train_input))\n",
    "\n",
    "    outfile = open(filename,'wb')\n",
    "    pickle.dump(train_input, outfile)\n",
    "    outfile.close()\n",
    "\n",
    "    print('saved successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb6943e6070>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(train_input[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_input, train_labels, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    from https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) #in channels, out channels (AKA # of kernels), kernel size\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) \n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "#         x = F.max_pool2d(F.leaky_relu(self.conv1(x), 0.01), (2, 2)) #trying with leaky\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "#         x = F.max_pool2d(F.leaky_relu(self.conv2(x), 0.01), 2) #trying with leaky\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "#         x = F.leaky_relu(self.fc1(x), 0.01)\n",
    "#         x = F.leaky_relu(self.fc2(x), 0.01)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x256 and 400x120)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-a1f2a5c8d0ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-ec43d3d0924b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#         x = F.max_pool2d(F.leaky_relu(self.conv2(x), 0.01), 2) #trying with leaky\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# flatten all dimensions except the batch dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m#         x = F.leaky_relu(self.fc1(x), 0.01)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x256 and 400x120)"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 28, 28)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
